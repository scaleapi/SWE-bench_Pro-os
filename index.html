<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SWE-Bench Pro</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 25%, #f093fb 50%, #4facfe 100%);
            min-height: 100vh;
            padding: 40px 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        .header {
            text-align: center;
            margin-bottom: 60px;
        }

        h1 {
            font-size: 3.5rem;
            font-weight: 800;
            color: #ffffff;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .subtitle {
            font-size: 1.25rem;
            color: #ffffff;
            margin-top: 10px;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
        }

        .buttons {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-top: 30px;
            flex-wrap: wrap;
        }

        .btn {
            padding: 12px 28px;
            border: 2px solid #3b82f6;
            background: white;
            border-radius: 10px;
            font-size: 1rem;
            font-weight: 600;
            color: #3b82f6;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }

        .btn:hover {
            background: #3b82f6;
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(59, 130, 246, 0.3);
        }

        .leaderboard-section {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
        }

        .leaderboard-title {
            font-size: 2rem;
            font-weight: 700;
            color: #1f2937;
            margin-bottom: 30px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
        }

        thead {
            background: #f3f4f6;
        }

        th {
            padding: 16px;
            text-align: left;
            font-weight: 600;
            color: #374151;
            border-bottom: 2px solid #e5e7eb;
        }

        th:nth-child(2), th:nth-child(3) {
            text-align: center;
        }

        th:last-child {
            text-align: center;
        }

        tbody tr {
            border-bottom: 1px solid #e5e7eb;
            transition: background 0.2s ease;
        }

        tbody tr:hover {
            background: #f9fafb;
        }

        td {
            padding: 16px;
            color: #1f2937;
        }

        td:nth-child(2), td:nth-child(3) {
            text-align: center;
        }

        td:last-child {
            text-align: center;
        }

        .model-name {
            font-weight: 500;
        }

        .model-icons {
            display: inline-flex;
            gap: 4px;
            margin-right: 8px;
            font-size: 1.2rem;
        }

        .resolved-score {
            font-size: 1.25rem;
            font-weight: 700;
            color: #059669;
        }

        .z-score {
            font-size: 1.1rem;
            font-weight: 600;
        }

        .z-score.positive {
            color: #059669;
        }

        .z-score.negative {
            color: #dc2626;
        }

        .link-icon {
            color: #3b82f6;
            text-decoration: none;
            font-size: 1.2rem;
            transition: transform 0.2s ease;
            display: inline-block;
        }

        .link-icon:hover {
            transform: scale(1.2);
        }

        .about-section {
            background: white;
            border-radius: 20px;
            padding: 40px;
            margin-top: 40px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
        }

        .about-section h2 {
            font-size: 1.75rem;
            font-weight: 700;
            color: #1f2937;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        .about-section h2:first-child {
            margin-top: 0;
        }

        .about-section p {
            color: #4b5563;
            line-height: 1.7;
            margin-bottom: 15px;
        }

        .about-section a {
            color: #3b82f6;
            text-decoration: none;
        }

        .about-section a:hover {
            text-decoration: underline;
        }

        .citation-box {
            background: #f9fafb;
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
            white-space: pre-wrap;
            color: #1f2937;
        }

        .disclaimer {
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #e5e7eb;
            color: #6b7280;
            font-size: 0.9rem;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2.5rem;
            }

            .leaderboard-section {
                padding: 20px;
                overflow-x: auto;
            }

            .about-section {
                padding: 20px;
            }

            table {
                font-size: 0.9rem;
            }

            th, td {
                padding: 12px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>SWE-Bench Pro</h1>
            <p class="subtitle">Evaluating AI Agents on Challenging Long-Horizon SWE Tasks</p>
            <div class="buttons">
                <a href="https://scale.com/leaderboard/swe_bench_pro_public" class="btn" target="_blank">üèÜ Official Leaderboard</a>
                <a href="https://arxiv.org/abs/2509.16941" class="btn" target="_blank">üìÑ Paper</a>
                <a href="https://github.com/scaleapi/SWE-bench_Pro-os" class="btn" target="_blank">üíª Code</a>
                <a href="https://huggingface.co/datasets/ScaleAI/SWE-bench_Pro" class="btn" target="_blank">üíæ Data</a>
                <a href="https://docs.google.com/forms/d/e/1FAIpQLScBjMAoPnm52nUSyOgO_iyWELuCrwjMKm0xzE2s6u-xSRBHug/viewform?usp=dialog" class="btn" target="_blank">üì§ Submit</a>
            </div>
        </div>

        <div class="leaderboard-section">
            <h2 class="leaderboard-title">Leaderboard</h2>
            <table id="leaderboardTable">
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>% Resolved</th>
                        <th>(+/-)</th>
                        <th>Link</th>
                    </tr>
                </thead>
                <tbody>
                    <tr data-score="43.72">
                        <td>
                            <span class="model-icons">ü•á</span>
                            <span class="model-name">SWE-Agent + claude-4-5-Sonnet</span>
                        </td>
                        <td><span class="resolved-score">43.72</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                    <tr data-score="42.70">
                        <td>
                            <span class="model-icons">ü•à</span>
                            <span class="model-name">SWE-Agent + claude-4-Sonnet</span>
                        </td>
                        <td><span class="resolved-score">42.70</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                    <tr data-score="39.45">
                        <td>
                            <span class="model-icons">ü•â</span>
                            <span class="model-name">SWE-Agent + claude-4-5-haiku</span>
                        </td>
                        <td><span class="resolved-score">39.45</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                    <tr data-score="36.30">
                        <td>
                            <span class="model-name">SWE-Agent + gpt-5-2025-08-07 (High)</span>
                        </td>
                        <td><span class="resolved-score">36.30</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                    <tr data-score="35.52">
                        <td>
                            <span class="model-name">SWE-Agent + glm-4.5</span>
                        </td>
                        <td><span class="resolved-score">35.52</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                    <tr data-score="27.67">
                        <td>
                            <span class="model-name">SWE-Agent + kimi-k2-instruct</span>
                        </td>
                        <td><span class="resolved-score">27.67</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                    <tr data-score="16.20">
                        <td>
                            <span class="model-name">SWE-Agent + gpt-oss-120b</span>
                        </td>
                        <td><span class="resolved-score">16.20</span></td>
                        <td><span class="z-score"></span></td>
                        <td><a href="https://github.com/scaleapi/SWE-bench_Pro-os/tree/main/traj" class="link-icon" target="_blank">üîó</a></td>
                    </tr>
                </tbody>
            </table>
            <p style="margin-top: 20px; color: #6b7280; font-size: 0.95rem; line-height: 1.6;">
                Note that these results are initial runs and subject to change, pending an official announcement from Scale. Models are run with an uncapped cost and with a turn limit of 250.<br><br>
                The (+/-) column shows the 95% confidence interval (margin of error) for each score, calculated using binomial proportion statistics (total problems: 730).
            </p>
        </div>

        <div class="about-section">
            <h2>About</h2>
            <p>
                We introduce SWE-Bench Pro, a substantially more challenging benchmark that builds upon the best practices of SWE-BENCH, but is explicitly designed to capture realistic, complex, enterprise-level problems beyond the scope of SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of 41 actively maintained repositories spanning business applications, B2B services, and developer tools. The benchmark is partitioned into a public set with open access to problems sourced from 11 repositories, a held-out set of 12 repositories and a commercial set of 18 proprietary repositories where we have formal partnership agreements with early-stage startups. Problems in the held-out and the commercial set are not publicly accessible, but we release results on the commercial set. Our benchmark features long-horizon tasks that may require hours to days for a professional software engineer to complete, often involving patches across multiple files and substantial code modifications. All tasks are human-verified and augmented with sufficient context to ensure resolvability. In our evaluation of widely used coding models, under a unified scaffold, we observe that their performance on SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest score to date at 23.3%. To better understand these limitations, we cluster the failure modes observed in the collected agent trajectories for a clearer characterization of the error patterns exhibited by current models. Overall, SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully captures the complexity and diversity of real-world software development, advancing the pursuit of truly autonomous software engineering agents at a professional level.
            </p>

            <h2>Citation</h2>
            <p>
                If you found <a href="https://arxiv.org/abs/2509.16941" target="_blank">SWE-bench Pro</a> helpful for your work, please cite as follows:
            </p>

            <div class="citation-box">@inproceedings{Deng2025SWEBenchPC,
    title={SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?},
    author={Xiang Deng and Jeff Da and Edwin Pan and Yan He and Charles Ide and Kanak Garg and Niklas Lauffer and Andrew Park and Nitin Pasari and Chetan Rane and Karmini Sampath and Maya Krishnan and Srivatsa Kundurthy and Sean M. Hendryx and Zifan Wang and Chen Bo Calvin Zhang and Noah Jacobson and Bing Liu and Brad Kenstler},
    year={2025},
    url={https://api.semanticscholar.org/CorpusID:281421060}
}</div>

            <div class="citation-box">@inproceedings{jimenez2024swebench,
     title={SWE-bench: Can Language Models Resolve Real-world Github Issues?},
     author={Carlos E Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik R Narasimhan},
     booktitle={The Twelfth International Conference on Learning Representations},
     year={2024},
     url={https://openreview.net/forum?id=VTF8yNQM66}
}</div>
            <p class="disclaimer">
            </p>
        </div>
    </div>

    <script>
        // Calculate confidence intervals for the leaderboard
        function calculateConfidenceIntervals() {
            const totalProblems = 730;
            const rows = document.querySelectorAll('#leaderboardTable tbody tr');
            const zScore = 1.96; // 95% confidence interval
            
            // Calculate and display confidence intervals
            rows.forEach((row) => {
                const percentage = parseFloat(row.getAttribute('data-score')) / 100;
                const solvedProblems = Math.round(percentage * totalProblems);
                
                // Calculate standard error for binomial proportion
                // SE = sqrt(p * (1-p) / n)
                const standardError = Math.sqrt((percentage * (1 - percentage)) / totalProblems);
                
                // Calculate margin of error (in percentage points)
                const marginOfError = zScore * standardError * 100;
                
                const ciElement = row.querySelector('.z-score');
                
                // Format as ¬± value
                ciElement.textContent = '¬±' + marginOfError.toFixed(2);
                
                // Always use positive (green) color since it's a confidence interval
                ciElement.classList.add('positive');
            });
        }
        
        // Run calculation when page loads
        document.addEventListener('DOMContentLoaded', calculateConfidenceIntervals);
    </script>
</body>
</html>